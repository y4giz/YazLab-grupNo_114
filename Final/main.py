# -*- coding: utf-8 -*-
"""LowData5Algo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Zlgqfim9XOZaqjKT17rCi_cQsNAxo6V
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from transformers import (
    ElectraTokenizer, TFElectraForSequenceClassification,
    AlbertTokenizer, TFAlbertForSequenceClassification,
    BertTokenizer, TFBertForSequenceClassification,
    RobertaTokenizer, TFRobertaForSequenceClassification,
    DebertaTokenizer, TFDebertaForSequenceClassification
)

class TransformerClassifier:
    def __init__(self, model_name):
        self.model_name = model_name
        self.tokenizer = None
        self.model = None
        self.setup_model()

    def setup_model(self):
        model_configs = {
            'electra': (ElectraTokenizer, TFElectraForSequenceClassification, 'google/electra-small-discriminator'),
            'albert': (AlbertTokenizer, TFAlbertForSequenceClassification, 'albert-base-v2'),
            'bert': (BertTokenizer, TFBertForSequenceClassification, 'bert-base-uncased'),
            'roberta': (RobertaTokenizer, TFRobertaForSequenceClassification, 'roberta-base'),
            'deberta': (DebertaTokenizer, TFDebertaForSequenceClassification, 'microsoft/deberta-base')
        }

        if self.model_name not in model_configs:
            raise ValueError(f"Model {self.model_name} not supported. Choose from: {list(model_configs.keys())}")

        TokenizerClass, ModelClass, pretrained_model = model_configs[self.model_name]
        self.tokenizer = TokenizerClass.from_pretrained(pretrained_model)
        self.model = ModelClass.from_pretrained(pretrained_model, num_labels=2)

    def combine_features(self, row):
        """Tüm özellikleri birleştirerek tek bir metin oluşturur"""
        combined = f"METHOD: {row['method']} URL: {row['url']} "
        if row['data']:
            combined += f"DATA: {row['data']} "
        return combined

    def prepare_data(self, data_path, max_length=256, batch_size=16):
        # Load data
        data = pd.read_json(data_path)

        # Tüm özellikleri birleştir
        data['combined_features'] = data.apply(self.combine_features, axis=1)

        # Split data
        train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

        # Tokenize (artık combined_features'ı kullanıyoruz)
        train_encodings = self.tokenizer(
            train_data['combined_features'].tolist(),
            truncation=True,
            padding=True,
            max_length=max_length,
            return_tensors="tf"
        )

        test_encodings = self.tokenizer(
            test_data['combined_features'].tolist(),
            truncation=True,
            padding=True,
            max_length=max_length,
            return_tensors="tf"
        )

        # Create TensorFlow datasets
        train_dataset = tf.data.Dataset.from_tensor_slices((
            dict(train_encodings),
            tf.convert_to_tensor(train_data['isAttack'].values)
        )).shuffle(1000).batch(batch_size)

        test_dataset = tf.data.Dataset.from_tensor_slices((
            dict(test_encodings),
            tf.convert_to_tensor(test_data['isAttack'].values)
        )).batch(batch_size)

        return train_dataset, test_dataset, test_data['isAttack'].values

    def train_and_evaluate(self, train_dataset, test_dataset, test_labels, epochs=1):
        # Compile the model
        optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)
        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
        metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]

        self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)

        # Train the model
        self.model.fit(
            train_dataset,
            validation_data=test_dataset,
            epochs=epochs,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(
                    monitor='val_loss',
                    patience=2,
                    restore_best_weights=True
                )
            ],
            verbose=1
        )

        # Get predictions
        predictions = self.model.predict(test_dataset, verbose=0)
        preds = np.argmax(predictions.logits, axis=-1)

        # Calculate metrics
        metrics = self.calculate_metrics(test_labels, preds)

        # Plot results
        self.plot_results(test_labels, preds, metrics)

        return metrics

    def calculate_metrics(self, true_labels, predictions):
        return {
            'accuracy': accuracy_score(true_labels, predictions),
            'precision': precision_score(true_labels, predictions),
            'recall': recall_score(true_labels, predictions),
            'f1': f1_score(true_labels, predictions),
            'confusion_matrix': confusion_matrix(true_labels, predictions),
            'roc': roc_curve(true_labels, predictions),
            'auc': auc(*roc_curve(true_labels, predictions)[:2])
        }

    def plot_results(self, true_labels, predictions, metrics):
        # Confusion Matrix
        plt.figure(figsize=(12, 5))
        plt.subplot(1, 2, 1)
        sns.heatmap(metrics['confusion_matrix'], annot=True, fmt='d', cmap='Blues')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title(f'Confusion Matrix - {self.model_name.upper()}')

        # ROC Curve
        plt.subplot(1, 2, 2)
        fpr, tpr, _ = metrics['roc']
        plt.plot(fpr, tpr, label=f'AUC = {metrics["auc"]:.2f}')
        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title(f'ROC Curve - {self.model_name.upper()}')
        plt.legend()
        plt.tight_layout()
        plt.show()

def run_all_models(data_path):
    models = ['deberta','electra', 'albert', 'bert', 'roberta']
    results = {}

    for model_name in models:
        print(f"\nTraining and evaluating {model_name.upper()}...")
        classifier = TransformerClassifier(model_name)
        train_dataset, test_dataset, test_labels = classifier.prepare_data(data_path)
        metrics = classifier.train_and_evaluate(train_dataset, test_dataset, test_labels)
        results[model_name] = metrics

        print(f"\n{model_name.upper()} Results:")
        print(f"Accuracy: {metrics['accuracy']:.4f}")
        print(f"Precision: {metrics['precision']:.4f}")
        print(f"Recall: {metrics['recall']:.4f}")
        print(f"F1-Score: {metrics['f1']:.4f}")
        print(f"AUC: {metrics['auc']:.4f}")

    return results

if __name__ == "__main__":
    data_path = '5kdata.json'
    results = run_all_models(data_path)
