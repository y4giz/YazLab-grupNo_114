# -*- coding: utf-8 -*-
"""bir.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17ktxH6WiSNomNfbL5tnrllYyR6CjT1sG
"""

import pandas as pd
import numpy as np
import time
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, roc_curve
)
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
from google.colab import drive

def load_and_preprocess_data(file_path):
    """Load and preprocess the JSON data."""
    data = pd.read_json(file_path)
    data['isAttack'] = data['isAttack'].astype(int)  # Ensure target is numeric
    return data

def plot_roc_curve(fpr, tpr, auc_score):
    """Plot the ROC curve."""
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='blue', label=f'AUC = {auc_score:.2f}')
    plt.plot([0, 1], [0, 1], color='red', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend()
    plt.show()

def plot_confusion_matrix(cm, classes):
    """Plot the confusion matrix."""
    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    thresh = cm.max() / 2.
    for i, j in np.ndindex(cm.shape):
        plt.text(j, i, f'{cm[i, j]}',
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

def evaluate_model(model, X_test, y_test):
    """Evaluate model performance."""
    y_pred = model.predict(X_test)
    y_pred_prob = model.predict_proba(X_test)[:, 1]

    acc = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_pred_prob)

    cm = confusion_matrix(y_test, y_pred)
    plot_confusion_matrix(cm, classes=['No Attack', 'Attack'])

    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    plot_roc_curve(fpr, tpr, auc)

    return acc, precision, recall, f1, auc

# Google Drive integration
drive.mount('/content/drive')
data_path = '/content/drive/My Drive/Colab Notebooks/5kdata.json'

# Step 1: Load and preprocess data
data = load_and_preprocess_data(data_path)

# Step 2: Prepare features and labels
X = data[['method', 'url', 'data']]
y = data['isAttack']

# Encode categorical features
le_method = LabelEncoder()
le_url = LabelEncoder()
le_data = LabelEncoder()

X['method'] = le_method.fit_transform(X['method'])
X['url'] = le_url.fit_transform(X['url'])
X['data'] = le_data.fit_transform(X['data'])

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 3: Split data into training and testing # Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Step 4: Train a Random Forest model
model = RandomForestClassifier(n_estimators=100, random_state=42)
start_time = time.time()
model.fit(X_train, y_train)
training_time = time.time() - start_time

# Step 5: Evaluate the model
evaluation_results = evaluate_model(model, X_test, y_test)

# Display results
print("Evaluation Results:")
print(f"Accuracy: {evaluation_results[0]:.2f}")
print(f"Precision: {evaluation_results[1]:.2f}")
print(f"Recall: {evaluation_results[2]:.2f}")
print(f"F1-Score: {evaluation_results[3]:.2f}")
print(f"AUC: {evaluation_results[4]:.2f}")
print(f"Training Time: {training_time:.2f} seconds")

